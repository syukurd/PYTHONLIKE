{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "dataset = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/pythonTutorial/online_raw.csv')\r\n",
    "print('Shape dataset:', dataset.shape)\r\n",
    "print('\\nLima data teratas:\\n', dataset.head())\r\n",
    "print('\\nInformasi dataset:')\r\n",
    "print(dataset.info())\r\n",
    "print('\\nStatistik deskriptif:\\n', dataset.describe())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan correlasi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_corr = dataset.corr()\r\n",
    "print('Korelasi dataset : \\n', dataset.corr())\r\n",
    "print('Distribusi Label (Revenue):\\n', dataset['Revenue'].value_counts())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_corr = dataset.corr()\r\n",
    "print('Korelasi dataset : \\n', dataset.corr())\r\n",
    "print('Distribusi Label (Revenue):\\n', dataset['Revenue'].value_counts())\r\n",
    "# Tugas praktek\r\n",
    "print('Korelasi BounceRates-ExitRates: ',dataset_corr.loc['ExitRates','BounceRates'])\r\n",
    "print('Korelasi Revenue-PageValues: ', dataset_corr.loc['Revenue','PageValues'])\r\n",
    "print('Korelasi TrafficType-Weekend: ', dataset_corr.loc['TrafficType','Weekend'])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "# checking the Distribution of customers on Revenue\r\n",
    "plt.rcParams['figure.figsize'] = (12,5)\r\n",
    "plt.subplot(1, 2, 1)\r\n",
    "sns.countplot(dataset['Revenue'], palette = 'pastel')\r\n",
    "plt.title('Buy or Not', fontsize = 20)\r\n",
    "plt.xlabel('Revenue or not', fontsize = 14)\r\n",
    "plt.ylabel('count', fontsize = 14)\r\n",
    "\r\n",
    "# checking the Distribution of customers on Weekend\r\n",
    "plt.subplot(1, 2, 2)\r\n",
    "sns.countplot(dataset['Weekend'], palette = 'inferno')\r\n",
    "plt.title('Purchase on Weekends', fontsize = 20)\r\n",
    "plt.xlabel('Weekend or not', fontsize = 14)\r\n",
    "plt.ylabel('count', fontsize = 14)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "# visualizing the distribution of customers around the Region\r\n",
    "plt.hist(dataset['Region'], color = 'lightblue')\r\n",
    "plt.title('Distribution of Customers', fontsize = 20)\r\n",
    "plt.xlabel('Region Codes', fontsize = 14)\r\n",
    "plt.ylabel('Count Users', fontsize = 14)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#checking missing value for each feature  \r\n",
    "print('Checking missing value for each feature:')\r\n",
    "print(dataset.isnull().sum())\r\n",
    "#Counting total missing value\r\n",
    "print('\\nCounting total missing value:')\r\n",
    "print(dataset.isnull().sum().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan drop terhadap missing data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_clean = dataset.dropna()\r\n",
    "print('dataset yang sudah dibersihkan dari missing value ',dataset_clean.shape )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# cara lain untuk mengatasi missing value dengan cara impute missing value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cek data kosong sebelumnya\r\n",
    "print(dataset.isnull().sum())\r\n",
    "\r\n",
    "#cek jumlah data kosong \r\n",
    "print(dataset.isnull().sum().sum())\r\n",
    "\r\n",
    "#mengatasi dengan impute missing value\r\n",
    "dataset.fillna(dataset.mean(), inplace = True)\r\n",
    "\r\n",
    "# cek data kosong setelah di impute\r\n",
    "print(dataset.isnull().sum())\r\n",
    "\r\n",
    "#cek jumlah data kosong setelah di impute \r\n",
    "print(dataset.isnull().sum().sum())\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "dataset1 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/pythonTutorial/online_raw.csv')\r\n",
    "\r\n",
    "print(\"Before imputation:\")\r\n",
    "# Checking missing value for each feature  \r\n",
    "print(dataset1.isnull().sum())\r\n",
    "# Counting total missing value  \r\n",
    "print(dataset1.isnull().sum().sum())\r\n",
    "\r\n",
    "print(\"\\nAfter imputation:\")\r\n",
    "# Fill missing value with median of feature value  \r\n",
    "dataset1.fillna(dataset.mean(), inplace = True)\r\n",
    "# Checking missing value for each feature  \r\n",
    "print(dataset1.isnull().sum())\r\n",
    "# Counting total missing value  \r\n",
    "print(dataset1.isnull().sum().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan scaler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "#Define MinMaxScaler as scaler  \r\n",
    "scaler = MinMaxScaler()  \r\n",
    "#list all the feature that need to be scaled  \r\n",
    "scaling_column = ['Administrative','Administrative_Duration','Informational','Informational_Duration','ProductRelated','ProductRelated_Duration','BounceRates','ExitRates','PageValues']\r\n",
    "#Apply fit_transfrom to scale selected feature  \r\n",
    "dataset[scaling_column] = scaler.fit_transform(dataset[scaling_column])\r\n",
    "#Cheking min and max value of the scaling_column\r\n",
    "print(dataset[scaling_column].describe().T[['min','max']])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merubah string menjadi numerik dengan LabelEncoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "# Convert feature/column 'Month'\r\n",
    "LE = LabelEncoder()\r\n",
    "dataset['Month'] = LE.fit_transform(dataset['Month'])\r\n",
    "print(LE.classes_)\r\n",
    "print(np.sort(dataset['Month'].unique()))\r\n",
    "print('')\r\n",
    "\r\n",
    "# Convert feature/column 'VisitorType'\r\n",
    "LE = LabelEncoder()\r\n",
    "dataset['VisitorType'] = LE.fit_transform(dataset['VisitorType'])\r\n",
    "print(LE.classes_)\r\n",
    "print(np.sort(dataset['VisitorType'].unique()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# removing the target column Revenue from dataset and assigning to X\r\n",
    "X = dataset.drop(['Revenue'], axis = 1)\r\n",
    "# assigning the target column Revenue to y\r\n",
    "y = dataset['Revenue']\r\n",
    "# checking the shapes\r\n",
    "print(\"Shape of X\", X.shape)\r\n",
    "print(\"Shape of y\", y.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan Train dan test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "# splitting the X, and y\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\r\n",
    "# checking the shapes\r\n",
    "print(\"Shape of X_train :\", X_train)\r\n",
    "print(\"Shape of y_train :\", y_test.shape)\r\n",
    "print(\"Shape of X_test :\", X_test.shape)\r\n",
    "print(\"Shape of y_test :\", y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pemanggilan fungsi algoritma decisiontree dari sklearn atau disebut dengan model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "# Call the classifier\r\n",
    "model = DecisionTreeClassifier()\r\n",
    "# Fit the classifier to the training data\r\n",
    "model = model.fit(X_train, y_train)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Memprediksi Label dari testing dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Apply the classifier/model to the test data\r\n",
    "y_pred = model.predict(X_test)\r\n",
    "print(y_pred.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\r\n",
    "#Evaluasi model\r\n",
    "print('Training Akurasi', model.score(X_train,y_train))\r\n",
    "print('Training Akurasi', model.score(X_test,y_test))\r\n",
    "\r\n",
    "# confusion matrix\r\n",
    "print('\\nConfusion matrix:')\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "print(cm)\r\n",
    "\r\n",
    "# classification report\r\n",
    "print('\\nClassification report:')\r\n",
    "cr = classification_report(y_test, y_pred)\r\n",
    "print(cr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report\r\n",
    "\r\n",
    "# Call the classifier\r\n",
    "logreg = LogisticRegression()\r\n",
    "# Fit the classifier to the training data  \r\n",
    "logreg = logreg.fit(X_train,y_train)\r\n",
    "#Training Model: Predict \r\n",
    "y_pred = logreg.predict(X_test)\r\n",
    "\r\n",
    "#Evaluate Model Performance\r\n",
    "print('Training Accuracy :', model.score(X_train, y_train))  \r\n",
    "print('Testing Accuracy :', model.score( X_test, y_test))  \r\n",
    "\r\n",
    "# confusion matrix\r\n",
    "print('\\nConfusion matrix')  \r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "print(cm)\r\n",
    "\r\n",
    "# classification report  \r\n",
    "print('\\nClassification report')  \r\n",
    "cr = classification_report(y_test, y_pred)\r\n",
    "print(cr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan Decision tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "# splitting the data\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "\r\n",
    "# Call the classifier\r\n",
    "decision_tree = DecisionTreeClassifier()\r\n",
    "# Fit the classifier to the training data\r\n",
    "decision_tree = decision_tree.fit(X_train, y_train)\r\n",
    "\r\n",
    "# evaluating the decision_tree performance\r\n",
    "print('Training Accuracy :', decision_tree.score(X_train,y_train))\r\n",
    "print('Testing Accuracy :', decision_tree.score(X_test,y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy : 1.0\n",
      "Testing Accuracy : 0.8588807785888077\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model regresi terdiri atas 2 tipe yaitu :\r\n",
    "\r\n",
    "Simple regression model → model regresi paling sederhana, hanya terdiri dari satu feature (univariate) dan 1 target.\r\n",
    "Multiple regression model → sesuai namanya, terdiri dari lebih dari satu feature (multivariate).\r\n",
    "Adapun model regresi yang paling umum digunakan adalah Linear Regression.\r\n",
    "\r\n",
    " "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "“Oke, saya tahu kamu sudah enggak sabar. Sebelumnya kamu membuat modellingnya, saya jelaskan prosedur dan library yang tepat untuk digunakan ya, nanti saya akan email detail intruksinya.”\r\n",
    "\r\n",
    "Aku pun menunggu email dari Senja. Setelah beberapa menit, pesan yang kutunggu akhirnya muncul:\r\n",
    "\r\n",
    "Pisahkan dataset ke dalam Feature dan Label, gunakan fungsi .drop(). Pada dataset ini, label/target adalah variabel MEDV\r\n",
    "Checking dan print jumlah data setelah Dataset pisahkan ke dalam Feature dan Label, gunakan .shape()\r\n",
    "Bagi dataset ke dalam Training dan test dataset, 70% data digunakan untuk training dan 30% untuk testing, gunakan fungsi train_test_split() , dengan random_state = 0\r\n",
    "Checking dan print kembali jumlah data dengan fungsi .shape()\r\n",
    "Import LinearRegression dari sklearn.linear_model\r\n",
    "Deklarasikan  LinearRegression regressor dengan nama reg\r\n",
    "Fit regressor ke training dataset dengan .fit(), dan gunakan .predict() untuk memprediksi nilai dari testing dataset.\r\n",
    "“Kalau dibaca aja kelihatannya membingungkan, tapi kalau sudah dicoba pasti bisa, Aksara. Semangat!”\r\n",
    "\r\n",
    " \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#load dataset\r\n",
    "import pandas as pd\r\n",
    "housing = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/pythonTutorial/housing_boston.csv')\r\n",
    "#Data rescaling\r\n",
    "from sklearn import preprocessing\r\n",
    "data_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\r\n",
    "housing[['RM','LSTAT','PTRATIO','MEDV']] = data_scaler.fit_transform(housing[['RM','LSTAT','PTRATIO','MEDV']])\r\n",
    "# getting dependent and independent variables\r\n",
    "X = housing.drop(['MEDV'], axis = 1)\r\n",
    "y = housing['MEDV']\r\n",
    "# checking the shapes\r\n",
    "print('Shape of X:', X.shape)\r\n",
    "print('Shape of y:', y.shape)\r\n",
    "\r\n",
    "# splitting the data\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "# checking the shapes  \r\n",
    "print('Shape of X_train :', X_train.shape)\r\n",
    "print('Shape of y_train :', y_train.shape)\r\n",
    "print('Shape of X_test :', X_test.shape)\r\n",
    "print('Shape of y_test :', y_test.shape)\r\n",
    "\r\n",
    "##import regressor from Scikit-Learn\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "# Call the regressor\r\n",
    "reg = LinearRegression()\r\n",
    "# Fit the regressor to the training data  \r\n",
    "reg = reg.fit(X_train, y_train)\r\n",
    "# Apply the regressor/model to the test data  \r\n",
    "y_pred = reg.predict(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of X: (489, 3)\n",
      "Shape of y: (489,)\n",
      "Shape of X_train : (342, 3)\n",
      "Shape of y_train : (342,)\n",
      "Shape of X_test : (147, 3)\n",
      "Shape of y_test : (147,)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1896/3934731376.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Apply the regressor/model to the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}