{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "dataset = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/pythonTutorial/online_raw.csv')\r\n",
    "print('Shape dataset:', dataset.shape)\r\n",
    "print('\\nLima data teratas:\\n', dataset.head())\r\n",
    "print('\\nInformasi dataset:')\r\n",
    "print(dataset.info())\r\n",
    "print('\\nStatistik deskriptif:\\n', dataset.describe())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan correlasi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_corr = dataset.corr()\r\n",
    "print('Korelasi dataset : \\n', dataset.corr())\r\n",
    "print('Distribusi Label (Revenue):\\n', dataset['Revenue'].value_counts())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_corr = dataset.corr()\r\n",
    "print('Korelasi dataset : \\n', dataset.corr())\r\n",
    "print('Distribusi Label (Revenue):\\n', dataset['Revenue'].value_counts())\r\n",
    "# Tugas praktek\r\n",
    "print('Korelasi BounceRates-ExitRates: ',dataset_corr.loc['ExitRates','BounceRates'])\r\n",
    "print('Korelasi Revenue-PageValues: ', dataset_corr.loc['Revenue','PageValues'])\r\n",
    "print('Korelasi TrafficType-Weekend: ', dataset_corr.loc['TrafficType','Weekend'])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "# checking the Distribution of customers on Revenue\r\n",
    "plt.rcParams['figure.figsize'] = (12,5)\r\n",
    "plt.subplot(1, 2, 1)\r\n",
    "sns.countplot(dataset['Revenue'], palette = 'pastel')\r\n",
    "plt.title('Buy or Not', fontsize = 20)\r\n",
    "plt.xlabel('Revenue or not', fontsize = 14)\r\n",
    "plt.ylabel('count', fontsize = 14)\r\n",
    "\r\n",
    "# checking the Distribution of customers on Weekend\r\n",
    "plt.subplot(1, 2, 2)\r\n",
    "sns.countplot(dataset['Weekend'], palette = 'inferno')\r\n",
    "plt.title('Purchase on Weekends', fontsize = 20)\r\n",
    "plt.xlabel('Weekend or not', fontsize = 14)\r\n",
    "plt.ylabel('count', fontsize = 14)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "# visualizing the distribution of customers around the Region\r\n",
    "plt.hist(dataset['Region'], color = 'lightblue')\r\n",
    "plt.title('Distribution of Customers', fontsize = 20)\r\n",
    "plt.xlabel('Region Codes', fontsize = 14)\r\n",
    "plt.ylabel('Count Users', fontsize = 14)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#checking missing value for each feature  \r\n",
    "print('Checking missing value for each feature:')\r\n",
    "print(dataset.isnull().sum())\r\n",
    "#Counting total missing value\r\n",
    "print('\\nCounting total missing value:')\r\n",
    "print(dataset.isnull().sum().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan drop terhadap missing data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_clean = dataset.dropna()\r\n",
    "print('dataset yang sudah dibersihkan dari missing value ',dataset_clean.shape )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# cara lain untuk mengatasi missing value dengan cara impute missing value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cek data kosong sebelumnya\r\n",
    "print(dataset.isnull().sum())\r\n",
    "\r\n",
    "#cek jumlah data kosong \r\n",
    "print(dataset.isnull().sum().sum())\r\n",
    "\r\n",
    "#mengatasi dengan impute missing value\r\n",
    "dataset.fillna(dataset.mean(), inplace = True)\r\n",
    "\r\n",
    "# cek data kosong setelah di impute\r\n",
    "print(dataset.isnull().sum())\r\n",
    "\r\n",
    "#cek jumlah data kosong setelah di impute \r\n",
    "print(dataset.isnull().sum().sum())\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "dataset1 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/pythonTutorial/online_raw.csv')\r\n",
    "\r\n",
    "print(\"Before imputation:\")\r\n",
    "# Checking missing value for each feature  \r\n",
    "print(dataset1.isnull().sum())\r\n",
    "# Counting total missing value  \r\n",
    "print(dataset1.isnull().sum().sum())\r\n",
    "\r\n",
    "print(\"\\nAfter imputation:\")\r\n",
    "# Fill missing value with median of feature value  \r\n",
    "dataset1.fillna(dataset.mean(), inplace = True)\r\n",
    "# Checking missing value for each feature  \r\n",
    "print(dataset1.isnull().sum())\r\n",
    "# Counting total missing value  \r\n",
    "print(dataset1.isnull().sum().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan scaler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "#Define MinMaxScaler as scaler  \r\n",
    "scaler = MinMaxScaler()  \r\n",
    "#list all the feature that need to be scaled  \r\n",
    "scaling_column = ['Administrative','Administrative_Duration','Informational','Informational_Duration','ProductRelated','ProductRelated_Duration','BounceRates','ExitRates','PageValues']\r\n",
    "#Apply fit_transfrom to scale selected feature  \r\n",
    "dataset[scaling_column] = scaler.fit_transform(dataset[scaling_column])\r\n",
    "#Cheking min and max value of the scaling_column\r\n",
    "print(dataset[scaling_column].describe().T[['min','max']])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merubah string menjadi numerik dengan LabelEncoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "# Convert feature/column 'Month'\r\n",
    "LE = LabelEncoder()\r\n",
    "dataset['Month'] = LE.fit_transform(dataset['Month'])\r\n",
    "print(LE.classes_)\r\n",
    "print(np.sort(dataset['Month'].unique()))\r\n",
    "print('')\r\n",
    "\r\n",
    "# Convert feature/column 'VisitorType'\r\n",
    "LE = LabelEncoder()\r\n",
    "dataset['VisitorType'] = LE.fit_transform(dataset['VisitorType'])\r\n",
    "print(LE.classes_)\r\n",
    "print(np.sort(dataset['VisitorType'].unique()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# removing the target column Revenue from dataset and assigning to X\r\n",
    "X = dataset.drop(['Revenue'], axis = 1)\r\n",
    "# assigning the target column Revenue to y\r\n",
    "y = dataset['Revenue']\r\n",
    "# checking the shapes\r\n",
    "print(\"Shape of X\", X.shape)\r\n",
    "print(\"Shape of y\", y.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan Train dan test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "# splitting the X, and y\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\r\n",
    "# checking the shapes\r\n",
    "print(\"Shape of X_train :\", X_train)\r\n",
    "print(\"Shape of y_train :\", y_test.shape)\r\n",
    "print(\"Shape of X_test :\", X_test.shape)\r\n",
    "print(\"Shape of y_test :\", y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pemanggilan fungsi algoritma decisiontree dari sklearn atau disebut dengan model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "# Call the classifier\r\n",
    "model = DecisionTreeClassifier()\r\n",
    "# Fit the classifier to the training data\r\n",
    "model = model.fit(X_train, y_train)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Memprediksi Label dari testing dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Apply the classifier/model to the test data\r\n",
    "y_pred = model.predict(X_test)\r\n",
    "print(y_pred.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\r\n",
    "#Evaluasi model\r\n",
    "print('Training Akurasi', model.score(X_train,y_train))\r\n",
    "print('Training Akurasi', model.score(X_test,y_test))\r\n",
    "\r\n",
    "# confusion matrix\r\n",
    "print('\\nConfusion matrix:')\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "print(cm)\r\n",
    "\r\n",
    "# classification report\r\n",
    "print('\\nClassification report:')\r\n",
    "cr = classification_report(y_test, y_pred)\r\n",
    "print(cr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report\r\n",
    "\r\n",
    "# Call the classifier\r\n",
    "logreg = LogisticRegression()\r\n",
    "# Fit the classifier to the training data  \r\n",
    "logreg = logreg.fit(X_train,y_train)\r\n",
    "#Training Model: Predict \r\n",
    "y_pred = logreg.predict(X_test)\r\n",
    "\r\n",
    "#Evaluate Model Performance\r\n",
    "print('Training Accuracy :', model.score(X_train, y_train))  \r\n",
    "print('Testing Accuracy :', model.score( X_test, y_test))  \r\n",
    "\r\n",
    "# confusion matrix\r\n",
    "print('\\nConfusion matrix')  \r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "print(cm)\r\n",
    "\r\n",
    "# classification report  \r\n",
    "print('\\nClassification report')  \r\n",
    "cr = classification_report(y_test, y_pred)\r\n",
    "print(cr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy : 1.0\n",
      "Testing Accuracy :        Administrative  Administrative_Duration  Informational  \\\n",
      "12245        0.000000                 0.000294       0.000000   \n",
      "9704         0.592593                 0.053435       0.041667   \n",
      "9177         0.333333                 0.055202       0.000000   \n",
      "8848         0.000000                 0.000294       0.000000   \n",
      "2768         0.000000                 0.000294       0.000000   \n",
      "...               ...                      ...            ...   \n",
      "9606         0.074074                 0.011104       0.083333   \n",
      "9095         0.111111                 0.034561       0.000000   \n",
      "3172         0.222222                 0.081820       0.083333   \n",
      "8009         0.037037                 0.019560       0.041667   \n",
      "1672         0.074074                 0.006471       0.000000   \n",
      "\n",
      "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
      "12245                0.000392        0.104965                 0.048619   \n",
      "9704                 0.254963        0.160284                 0.125715   \n",
      "9177                 0.000392        0.103546                 0.025124   \n",
      "8848                 0.000392        0.002837                 0.000016   \n",
      "2768                 0.000392        0.001418                 0.000016   \n",
      "...                       ...             ...                      ...   \n",
      "9606                 0.003921        0.028369                 0.006168   \n",
      "9095                 0.000392        0.021277                 0.005022   \n",
      "3172                 0.353477        0.034043                 0.022655   \n",
      "8009                 0.015488        0.185816                 0.061019   \n",
      "1672                 0.000392        0.092199                 0.045051   \n",
      "\n",
      "       BounceRates  ExitRates  PageValues  SpecialDay  Month  \\\n",
      "12245     0.047297   0.214296     0.00000         0.0      7   \n",
      "9704      0.039683   0.134041     0.00000         0.0      1   \n",
      "9177      0.051477   0.095544     0.00000         0.0      7   \n",
      "8848      1.000000   1.000000     0.00000         0.0      7   \n",
      "2768      1.000000   1.000000     0.00000         1.0      6   \n",
      "...            ...        ...         ...         ...    ...   \n",
      "9606      0.041667   0.169363     0.00000         0.0      7   \n",
      "9095      0.000000   0.029412     0.00000         0.0      1   \n",
      "3172      0.000000   0.019231     0.00000         0.0      6   \n",
      "8009      0.044444   0.114352     0.00000         0.0      7   \n",
      "1672      0.000000   0.014925     0.22302         0.0      5   \n",
      "\n",
      "       OperatingSystems  Browser  Region  TrafficType  VisitorType  Weekend  \n",
      "12245                 2        2       1            2            2    False  \n",
      "9704                  2        6       7            1            2    False  \n",
      "9177                  3        2       8            2            2     True  \n",
      "8848                  3        2       5           20            2    False  \n",
      "2768                  4        1       2            3            2     True  \n",
      "...                 ...      ...     ...          ...          ...      ...  \n",
      "9606                  1        1       3            6            2    False  \n",
      "9095                  1        1       4            6            2     True  \n",
      "3172                  2        4       4            2            0     True  \n",
      "8009                  3        2       3            1            2    False  \n",
      "1672                  2        2       4            2            0    False  \n",
      "\n",
      "[2466 rows x 17 columns] 12245    False\n",
      "9704     False\n",
      "9177     False\n",
      "8848     False\n",
      "2768     False\n",
      "         ...  \n",
      "9606     False\n",
      "9095     False\n",
      "3172     False\n",
      "8009     False\n",
      "1672      True\n",
      "Name: Revenue, Length: 2466, dtype: bool\n",
      "\n",
      "Confusion matrix\n",
      "[[2009   35]\n",
      " [ 315  107]]\n",
      "\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.98      0.92      2044\n",
      "        True       0.75      0.25      0.38       422\n",
      "\n",
      "    accuracy                           0.86      2466\n",
      "   macro avg       0.81      0.62      0.65      2466\n",
      "weighted avg       0.85      0.86      0.83      2466\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}