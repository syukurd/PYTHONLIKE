{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "dataset = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/pythonTutorial/online_raw.csv')\r\n",
    "print('Shape dataset:', dataset.shape)\r\n",
    "print('\\nLima data teratas:\\n', dataset.head())\r\n",
    "print('\\nInformasi dataset:')\r\n",
    "print(dataset.info())\r\n",
    "print('\\nStatistik deskriptif:\\n', dataset.describe())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan correlasi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_corr = dataset.corr()\r\n",
    "print('Korelasi dataset : \\n', dataset.corr())\r\n",
    "print('Distribusi Label (Revenue):\\n', dataset['Revenue'].value_counts())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_corr = dataset.corr()\r\n",
    "print('Korelasi dataset : \\n', dataset.corr())\r\n",
    "print('Distribusi Label (Revenue):\\n', dataset['Revenue'].value_counts())\r\n",
    "# Tugas praktek\r\n",
    "print('Korelasi BounceRates-ExitRates: ',dataset_corr.loc['ExitRates','BounceRates'])\r\n",
    "print('Korelasi Revenue-PageValues: ', dataset_corr.loc['Revenue','PageValues'])\r\n",
    "print('Korelasi TrafficType-Weekend: ', dataset_corr.loc['TrafficType','Weekend'])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "# checking the Distribution of customers on Revenue\r\n",
    "plt.rcParams['figure.figsize'] = (12,5)\r\n",
    "plt.subplot(1, 2, 1)\r\n",
    "sns.countplot(dataset['Revenue'], palette = 'pastel')\r\n",
    "plt.title('Buy or Not', fontsize = 20)\r\n",
    "plt.xlabel('Revenue or not', fontsize = 14)\r\n",
    "plt.ylabel('count', fontsize = 14)\r\n",
    "\r\n",
    "# checking the Distribution of customers on Weekend\r\n",
    "plt.subplot(1, 2, 2)\r\n",
    "sns.countplot(dataset['Weekend'], palette = 'inferno')\r\n",
    "plt.title('Purchase on Weekends', fontsize = 20)\r\n",
    "plt.xlabel('Weekend or not', fontsize = 14)\r\n",
    "plt.ylabel('count', fontsize = 14)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "# visualizing the distribution of customers around the Region\r\n",
    "plt.hist(dataset['Region'], color = 'lightblue')\r\n",
    "plt.title('Distribution of Customers', fontsize = 20)\r\n",
    "plt.xlabel('Region Codes', fontsize = 14)\r\n",
    "plt.ylabel('Count Users', fontsize = 14)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#checking missing value for each feature  \r\n",
    "print('Checking missing value for each feature:')\r\n",
    "print(dataset.isnull().sum())\r\n",
    "#Counting total missing value\r\n",
    "print('\\nCounting total missing value:')\r\n",
    "print(dataset.isnull().sum().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan drop terhadap missing data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_clean = dataset.dropna()\r\n",
    "print('dataset yang sudah dibersihkan dari missing value ',dataset_clean.shape )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# cara lain untuk mengatasi missing value dengan cara impute missing value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cek data kosong sebelumnya\r\n",
    "print(dataset.isnull().sum())\r\n",
    "\r\n",
    "#cek jumlah data kosong \r\n",
    "print(dataset.isnull().sum().sum())\r\n",
    "\r\n",
    "#mengatasi dengan impute missing value\r\n",
    "dataset.fillna(dataset.mean(), inplace = True)\r\n",
    "\r\n",
    "# cek data kosong setelah di impute\r\n",
    "print(dataset.isnull().sum())\r\n",
    "\r\n",
    "#cek jumlah data kosong setelah di impute \r\n",
    "print(dataset.isnull().sum().sum())\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "dataset1 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/pythonTutorial/online_raw.csv')\r\n",
    "\r\n",
    "print(\"Before imputation:\")\r\n",
    "# Checking missing value for each feature  \r\n",
    "print(dataset1.isnull().sum())\r\n",
    "# Counting total missing value  \r\n",
    "print(dataset1.isnull().sum().sum())\r\n",
    "\r\n",
    "print(\"\\nAfter imputation:\")\r\n",
    "# Fill missing value with median of feature value  \r\n",
    "dataset1.fillna(dataset.mean(), inplace = True)\r\n",
    "# Checking missing value for each feature  \r\n",
    "print(dataset1.isnull().sum())\r\n",
    "# Counting total missing value  \r\n",
    "print(dataset1.isnull().sum().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan scaler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "#Define MinMaxScaler as scaler  \r\n",
    "scaler = MinMaxScaler()  \r\n",
    "#list all the feature that need to be scaled  \r\n",
    "scaling_column = ['Administrative','Administrative_Duration','Informational','Informational_Duration','ProductRelated','ProductRelated_Duration','BounceRates','ExitRates','PageValues']\r\n",
    "#Apply fit_transfrom to scale selected feature  \r\n",
    "dataset[scaling_column] = scaler.fit_transform(dataset[scaling_column])\r\n",
    "#Cheking min and max value of the scaling_column\r\n",
    "print(dataset[scaling_column].describe().T[['min','max']])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merubah string menjadi numerik dengan LabelEncoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "# Convert feature/column 'Month'\r\n",
    "LE = LabelEncoder()\r\n",
    "dataset['Month'] = LE.fit_transform(dataset['Month'])\r\n",
    "print(LE.classes_)\r\n",
    "print(np.sort(dataset['Month'].unique()))\r\n",
    "print('')\r\n",
    "\r\n",
    "# Convert feature/column 'VisitorType'\r\n",
    "LE = LabelEncoder()\r\n",
    "dataset['VisitorType'] = LE.fit_transform(dataset['VisitorType'])\r\n",
    "print(LE.classes_)\r\n",
    "print(np.sort(dataset['VisitorType'].unique()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# removing the target column Revenue from dataset and assigning to X\r\n",
    "X = dataset.drop(['Revenue'], axis = 1)\r\n",
    "# assigning the target column Revenue to y\r\n",
    "y = dataset['Revenue']\r\n",
    "# checking the shapes\r\n",
    "print(\"Shape of X\", X.shape)\r\n",
    "print(\"Shape of y\", y.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan Train dan test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "# splitting the X, and y\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\r\n",
    "# checking the shapes\r\n",
    "print(\"Shape of X_train :\", X_train)\r\n",
    "print(\"Shape of y_train :\", y_test.shape)\r\n",
    "print(\"Shape of X_test :\", X_test.shape)\r\n",
    "print(\"Shape of y_test :\", y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pemanggilan fungsi algoritma decisiontree dari sklearn atau disebut dengan model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "# Call the classifier\r\n",
    "model = DecisionTreeClassifier()\r\n",
    "# Fit the classifier to the training data\r\n",
    "model = model.fit(X_train, y_train)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Memprediksi Label dari testing dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Apply the classifier/model to the test data\r\n",
    "y_pred = model.predict(X_test)\r\n",
    "print(y_pred.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\r\n",
    "#Evaluasi model\r\n",
    "print('Training Akurasi', model.score(X_train,y_train))\r\n",
    "print('Training Akurasi', model.score(X_test,y_test))\r\n",
    "\r\n",
    "# confusion matrix\r\n",
    "print('\\nConfusion matrix:')\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "print(cm)\r\n",
    "\r\n",
    "# classification report\r\n",
    "print('\\nClassification report:')\r\n",
    "cr = classification_report(y_test, y_pred)\r\n",
    "print(cr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report\r\n",
    "\r\n",
    "# Call the classifier\r\n",
    "logreg = LogisticRegression()\r\n",
    "# Fit the classifier to the training data  \r\n",
    "logreg = logreg.fit(X_train,y_train)\r\n",
    "#Training Model: Predict \r\n",
    "y_pred = logreg.predict(X_test)\r\n",
    "\r\n",
    "#Evaluate Model Performance\r\n",
    "print('Training Accuracy :', model.score(X_train, y_train))  \r\n",
    "print('Testing Accuracy :', model.score( X_test, y_test))  \r\n",
    "\r\n",
    "# confusion matrix\r\n",
    "print('\\nConfusion matrix')  \r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "print(cm)\r\n",
    "\r\n",
    "# classification report  \r\n",
    "print('\\nClassification report')  \r\n",
    "cr = classification_report(y_test, y_pred)\r\n",
    "print(cr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan Decision tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "# splitting the data\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "\r\n",
    "# Call the classifier\r\n",
    "decision_tree = DecisionTreeClassifier()\r\n",
    "# Fit the classifier to the training data\r\n",
    "decision_tree = decision_tree.fit(X_train, y_train)\r\n",
    "\r\n",
    "# evaluating the decision_tree performance\r\n",
    "print('Training Accuracy :', decision_tree.score(X_train,y_train))\r\n",
    "print('Testing Accuracy :', decision_tree.score(X_test,y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy : 1.0\n",
      "Testing Accuracy : 0.8588807785888077\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model regresi terdiri atas 2 tipe yaitu :\r\n",
    "\r\n",
    "Simple regression model → model regresi paling sederhana, hanya terdiri dari satu feature (univariate) dan 1 target.\r\n",
    "Multiple regression model → sesuai namanya, terdiri dari lebih dari satu feature (multivariate).\r\n",
    "Adapun model regresi yang paling umum digunakan adalah Linear Regression.\r\n",
    "\r\n",
    " "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}