{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "dataset = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/pythonTutorial/online_raw.csv')\r\n",
    "print('Shape dataset:', dataset.shape)\r\n",
    "print('\\nLima data teratas:\\n', dataset.head())\r\n",
    "print('\\nInformasi dataset:')\r\n",
    "print(dataset.info())\r\n",
    "print('\\nStatistik deskriptif:\\n', dataset.describe())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan correlasi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_corr = dataset.corr()\r\n",
    "print('Korelasi dataset : \\n', dataset.corr())\r\n",
    "print('Distribusi Label (Revenue):\\n', dataset['Revenue'].value_counts())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_corr = dataset.corr()\r\n",
    "print('Korelasi dataset : \\n', dataset.corr())\r\n",
    "print('Distribusi Label (Revenue):\\n', dataset['Revenue'].value_counts())\r\n",
    "# Tugas praktek\r\n",
    "print('Korelasi BounceRates-ExitRates: ',dataset_corr.loc['ExitRates','BounceRates'])\r\n",
    "print('Korelasi Revenue-PageValues: ', dataset_corr.loc['Revenue','PageValues'])\r\n",
    "print('Korelasi TrafficType-Weekend: ', dataset_corr.loc['TrafficType','Weekend'])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "# checking the Distribution of customers on Revenue\r\n",
    "plt.rcParams['figure.figsize'] = (12,5)\r\n",
    "plt.subplot(1, 2, 1)\r\n",
    "sns.countplot(dataset['Revenue'], palette = 'pastel')\r\n",
    "plt.title('Buy or Not', fontsize = 20)\r\n",
    "plt.xlabel('Revenue or not', fontsize = 14)\r\n",
    "plt.ylabel('count', fontsize = 14)\r\n",
    "\r\n",
    "# checking the Distribution of customers on Weekend\r\n",
    "plt.subplot(1, 2, 2)\r\n",
    "sns.countplot(dataset['Weekend'], palette = 'inferno')\r\n",
    "plt.title('Purchase on Weekends', fontsize = 20)\r\n",
    "plt.xlabel('Weekend or not', fontsize = 14)\r\n",
    "plt.ylabel('count', fontsize = 14)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "# visualizing the distribution of customers around the Region\r\n",
    "plt.hist(dataset['Region'], color = 'lightblue')\r\n",
    "plt.title('Distribution of Customers', fontsize = 20)\r\n",
    "plt.xlabel('Region Codes', fontsize = 14)\r\n",
    "plt.ylabel('Count Users', fontsize = 14)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#checking missing value for each feature  \r\n",
    "print('Checking missing value for each feature:')\r\n",
    "print(dataset.isnull().sum())\r\n",
    "#Counting total missing value\r\n",
    "print('\\nCounting total missing value:')\r\n",
    "print(dataset.isnull().sum().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan drop terhadap missing data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_clean = dataset.dropna()\r\n",
    "print('dataset yang sudah dibersihkan dari missing value ',dataset_clean.shape )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# cara lain untuk mengatasi missing value dengan cara impute missing value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cek data kosong sebelumnya\r\n",
    "print(dataset.isnull().sum())\r\n",
    "\r\n",
    "#cek jumlah data kosong \r\n",
    "print(dataset.isnull().sum().sum())\r\n",
    "\r\n",
    "#mengatasi dengan impute missing value\r\n",
    "dataset.fillna(dataset.mean(), inplace = True)\r\n",
    "\r\n",
    "# cek data kosong setelah di impute\r\n",
    "print(dataset.isnull().sum())\r\n",
    "\r\n",
    "#cek jumlah data kosong setelah di impute \r\n",
    "print(dataset.isnull().sum().sum())\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "dataset1 = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/pythonTutorial/online_raw.csv')\r\n",
    "\r\n",
    "print(\"Before imputation:\")\r\n",
    "# Checking missing value for each feature  \r\n",
    "print(dataset1.isnull().sum())\r\n",
    "# Counting total missing value  \r\n",
    "print(dataset1.isnull().sum().sum())\r\n",
    "\r\n",
    "print(\"\\nAfter imputation:\")\r\n",
    "# Fill missing value with median of feature value  \r\n",
    "dataset1.fillna(dataset.mean(), inplace = True)\r\n",
    "# Checking missing value for each feature  \r\n",
    "print(dataset1.isnull().sum())\r\n",
    "# Counting total missing value  \r\n",
    "print(dataset1.isnull().sum().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan scaler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "#Define MinMaxScaler as scaler  \r\n",
    "scaler = MinMaxScaler()  \r\n",
    "#list all the feature that need to be scaled  \r\n",
    "scaling_column = ['Administrative','Administrative_Duration','Informational','Informational_Duration','ProductRelated','ProductRelated_Duration','BounceRates','ExitRates','PageValues']\r\n",
    "#Apply fit_transfrom to scale selected feature  \r\n",
    "dataset[scaling_column] = scaler.fit_transform(dataset[scaling_column])\r\n",
    "#Cheking min and max value of the scaling_column\r\n",
    "print(dataset[scaling_column].describe().T[['min','max']])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merubah string menjadi numerik dengan LabelEncoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "# Convert feature/column 'Month'\r\n",
    "LE = LabelEncoder()\r\n",
    "dataset['Month'] = LE.fit_transform(dataset['Month'])\r\n",
    "print(LE.classes_)\r\n",
    "print(np.sort(dataset['Month'].unique()))\r\n",
    "print('')\r\n",
    "\r\n",
    "# Convert feature/column 'VisitorType'\r\n",
    "LE = LabelEncoder()\r\n",
    "dataset['VisitorType'] = LE.fit_transform(dataset['VisitorType'])\r\n",
    "print(LE.classes_)\r\n",
    "print(np.sort(dataset['VisitorType'].unique()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# removing the target column Revenue from dataset and assigning to X\r\n",
    "X = dataset.drop(['Revenue'], axis = 1)\r\n",
    "# assigning the target column Revenue to y\r\n",
    "y = dataset['Revenue']\r\n",
    "# checking the shapes\r\n",
    "print(\"Shape of X\", X.shape)\r\n",
    "print(\"Shape of y\", y.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan Train dan test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "# splitting the X, and y\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\r\n",
    "# checking the shapes\r\n",
    "print(\"Shape of X_train :\", X_train)\r\n",
    "print(\"Shape of y_train :\", y_test.shape)\r\n",
    "print(\"Shape of X_test :\", X_test.shape)\r\n",
    "print(\"Shape of y_test :\", y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pemanggilan fungsi algoritma decisiontree dari sklearn atau disebut dengan model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "# Call the classifier\r\n",
    "model = DecisionTreeClassifier()\r\n",
    "# Fit the classifier to the training data\r\n",
    "model = model.fit(X_train, y_train)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Memprediksi Label dari testing dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Apply the classifier/model to the test data\r\n",
    "y_pred = model.predict(X_test)\r\n",
    "print(y_pred.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\r\n",
    "#Evaluasi model\r\n",
    "print('Training Akurasi', model.score(X_train,y_train))\r\n",
    "print('Training Akurasi', model.score(X_test,y_test))\r\n",
    "\r\n",
    "# confusion matrix\r\n",
    "print('\\nConfusion matrix:')\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "print(cm)\r\n",
    "\r\n",
    "# classification report\r\n",
    "print('\\nClassification report:')\r\n",
    "cr = classification_report(y_test, y_pred)\r\n",
    "print(cr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report\r\n",
    "\r\n",
    "# Call the classifier\r\n",
    "logreg = LogisticRegression()\r\n",
    "# Fit the classifier to the training data  \r\n",
    "logreg = logreg.fit(X_train,y_train)\r\n",
    "#Training Model: Predict \r\n",
    "y_pred = logreg.predict(X_test)\r\n",
    "\r\n",
    "#Evaluate Model Performance\r\n",
    "print('Training Accuracy :', model.score(X_train, y_train))  \r\n",
    "print('Testing Accuracy :', model.score( X_test, y_test))  \r\n",
    "\r\n",
    "# confusion matrix\r\n",
    "print('\\nConfusion matrix')  \r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "print(cm)\r\n",
    "\r\n",
    "# classification report  \r\n",
    "print('\\nClassification report')  \r\n",
    "cr = classification_report(y_test, y_pred)\r\n",
    "print(cr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melakukan Decision tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "# splitting the data\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "\r\n",
    "# Call the classifier\r\n",
    "decision_tree = DecisionTreeClassifier()\r\n",
    "# Fit the classifier to the training data\r\n",
    "decision_tree = decision_tree.fit(X_train, y_train)\r\n",
    "\r\n",
    "# evaluating the decision_tree performance\r\n",
    "print('Training Accuracy :', decision_tree.score(X_train,y_train))\r\n",
    "print('Testing Accuracy :', decision_tree.score(X_test,y_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model regresi terdiri atas 2 tipe yaitu :\r\n",
    "\r\n",
    "Simple regression model → model regresi paling sederhana, hanya terdiri dari satu feature (univariate) dan 1 target.\r\n",
    "Multiple regression model → sesuai namanya, terdiri dari lebih dari satu feature (multivariate).\r\n",
    "Adapun model regresi yang paling umum digunakan adalah Linear Regression.\r\n",
    "\r\n",
    " "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "“Oke, saya tahu kamu sudah enggak sabar. Sebelumnya kamu membuat modellingnya, saya jelaskan prosedur dan library yang tepat untuk digunakan ya, nanti saya akan email detail intruksinya.”\r\n",
    "\r\n",
    "Aku pun menunggu email dari Senja. Setelah beberapa menit, pesan yang kutunggu akhirnya muncul:\r\n",
    "\r\n",
    "Pisahkan dataset ke dalam Feature dan Label, gunakan fungsi .drop(). Pada dataset ini, label/target adalah variabel MEDV\r\n",
    "Checking dan print jumlah data setelah Dataset pisahkan ke dalam Feature dan Label, gunakan .shape()\r\n",
    "Bagi dataset ke dalam Training dan test dataset, 70% data digunakan untuk training dan 30% untuk testing, gunakan fungsi train_test_split() , dengan random_state = 0\r\n",
    "Checking dan print kembali jumlah data dengan fungsi .shape()\r\n",
    "Import LinearRegression dari sklearn.linear_model\r\n",
    "Deklarasikan  LinearRegression regressor dengan nama reg\r\n",
    "Fit regressor ke training dataset dengan .fit(), dan gunakan .predict() untuk memprediksi nilai dari testing dataset.\r\n",
    "“Kalau dibaca aja kelihatannya membingungkan, tapi kalau sudah dicoba pasti bisa, Aksara. Semangat!”\r\n",
    "\r\n",
    " \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#load dataset\r\n",
    "import pandas as pd\r\n",
    "housing = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/pythonTutorial/housing_boston.csv')\r\n",
    "#Data rescaling\r\n",
    "from sklearn import preprocessing\r\n",
    "data_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\r\n",
    "housing[['RM','LSTAT','PTRATIO','MEDV']] = data_scaler.fit_transform(housing[['RM','LSTAT','PTRATIO','MEDV']])\r\n",
    "# getting dependent and independent variables\r\n",
    "X = housing.drop(['MEDV'], axis = 1)\r\n",
    "y = housing['MEDV']\r\n",
    "# checking the shapes\r\n",
    "print('Shape of X:', X.shape)\r\n",
    "print('Shape of y:', y.shape)\r\n",
    "\r\n",
    "# splitting the data\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "# checking the shapes  \r\n",
    "print('Shape of X_train :', X_train.shape)\r\n",
    "print('Shape of y_train :', y_train.shape)\r\n",
    "print('Shape of X_test :', X_test.shape)\r\n",
    "print('Shape of y_test :', y_test.shape)\r\n",
    "\r\n",
    "##import regressor from Scikit-Learn\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "# Call the regressor\r\n",
    "reg = LinearRegression()\r\n",
    "# Fit the regressor to the training data  \r\n",
    "reg = reg.fit(X_train, y_train)\r\n",
    "# Apply the regressor/model to the test data  \r\n",
    "y_pred = reg.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tugas Praktek\r\n",
    "\"Kalau kamu sudah paham evaluasi performa model regresi, sekaligus kamu coba hitung nilai MSE, MAE, dan RMSE dari linear modelnya, Aksara,” pinta Senja\r\n",
    "\r\n",
    " \r\n",
    "\r\n",
    "Aku baru mau mengutak-atik kodenya ketika email dari Senja muncul berisi intruksi:\r\n",
    "\r\n",
    "Import library yang digunakan: mean_squared_error, mean_absolute_error dari  sklearn.metrics dan numpy sebagai aliasnya yaitu np. Serta, import juga matplotlib.pyplot sebagai aliasnya, plt.\r\n",
    "Hitung dan print nilai MSE dan RMSE dengan menggunakan argumen y_test dan y_pred, untuk rmse gunakan np.sqrt()\r\n",
    "Buat scatter plot yang menggambarkan hasil prediksi (y_pred) dan harga actual (y_test)\r\n",
    " "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt \r\n",
    "\r\n",
    "#Calculating MSE, lower the value better it is. 0 means perfect prediction\r\n",
    "mse = mean_squared_error(y_test, y_pred)\r\n",
    "print('Mean squared error of testing set:', mse)\r\n",
    "#Calculating MAE\r\n",
    "mae = mean_absolute_error(y_test, y_pred)\r\n",
    "print('Mean absolute error of testing set:', mae)\r\n",
    "#Calculating RMSE\r\n",
    "rmse = np.sqrt(mse)\r\n",
    "print('Root Mean Squared Error of testing set:', rmse)\r\n",
    "\r\n",
    "#Plotting y_test dan y_pred\r\n",
    "plt.scatter(y_test, y_pred, c = 'green')\r\n",
    "plt.xlabel('Price Actual')\r\n",
    "plt.ylabel('Predicted value')\r\n",
    "plt.title('True value vs predicted value : Linear Regression')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "K-Means Clustering\r\n",
    "\"Jadi, Algorithm K-Means itu apa dan bagaimana cara kerjanya?” tanyaku antusias.\r\n",
    "\r\n",
    " “K-Means merupakan tipe clustering dengan centroid based (titik pusat). Artinya kesamaan dari objek/sampel dihitung dari seberapa dekat objek itu dengan centroid atau titik pusat.”\r\n",
    "\r\n",
    " \r\n",
    "\r\n",
    "Aku masih penasaran. “Jadi, bagaimana kita mengukur kedekatan objek dan centroid?”\r\n",
    "\r\n",
    " “Untuk menghitung kedekatan, digunakan perhitungan jarak antar 2 buah data atau jarak Minkowski. Saya share yah rumusnya,” ujar Senja.\r\n",
    "\r\n",
    "Aku menyimak isi rumus yang dibagikan Senja di slide presentasinya:\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "xi , xj adalah dua buah data yang akan dihitung jaraknya, dan p = dimensi/jumlah dari data\r\n",
    "\r\n",
    "Terdapat beberapa tipe perhitungan jarak yang dapat digunakan, yaitu :\r\n",
    "\r\n",
    "Jarak Manhattan di mana g = 1\r\n",
    "Jarak Euclidean di mana g = 2\r\n",
    "Jarak Chebychev di mana g = ∞\r\n",
    " “Nja, aku masih bingung, cara menentukan centroid bagaimana caranya?”\r\n",
    "\r\n",
    " \r\n",
    "\r\n",
    " “Untuk menentukan centroid, pada awalnya kita perlu mendefinisikan jumlah centroid (K) yang diinginkan, semisalnya kita menetapkan jumlah K = 3; maka pada awal iterasi, algorithm akan secara random menentukan 3 centroid. Setelah itu, objek/sample/data point yang lain akan dikelompokkan sebagai anggota dari salah satu centroid yang terdekat, sehingga terbentuk 3 cluster data. Sampai sini cukup dipahami?”\r\n",
    "\r\n",
    " \r\n",
    "\r\n",
    "“Yup, boleh lanjut, Nja,” sahutku mempersilakan Senja kembali menjelaskan.\r\n",
    "\r\n",
    "“Iterasi selanjutnya, titik-titik centroid diupdate atau berpindah ke titik yang lain, dan jarak dari data point yang lain ke centroid yang baru dihitung kembali, kemudian dikelompokkan kembali berdasarkan jarak terdekat ke centroid yang baru. Iterasi akan terus berlanjut hingga diperoleh cluster dengan error terkecil, dan posisi centroid tidak lagi berubah.”\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "“Kamu sudah bisa lihat di layar ya, Aksara. Menurutmu, apakah ada perbedaan prosedur antara unsupervised learning dan supervised learning?”\r\n",
    "\r\n",
    " \r\n",
    "\r\n",
    "Aku tahu ini pertanyaan untuk menguji pemahamanku.\r\n",
    "\r\n",
    "“Secara prosedur, tahap eksplorasi data untuk memahami karakteristik data, dan tahap preprocessing tetap dilakukan. Tetapi dalam unsupervised learning, kita tidak membagi dataset ke feature dan label; dan juga ke dalam training dan test dataset, karena pada dasarnya kita tidak memiliki informasi mengenai label/target data,” jawabku mantap.\r\n",
    "\r\n",
    " \r\n",
    "\r\n",
    "“Tampaknya kamu sudah paham. Saatnya kita mulai praktik membuat programnya.”\r\n",
    "\r\n",
    " \r\n",
    "\r\n",
    " "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}