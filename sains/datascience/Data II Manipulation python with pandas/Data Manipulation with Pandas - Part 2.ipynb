{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Append"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Buat series of int (s1) dan series of string (s2)\r\n",
    "s1 = pd.Series([1,2,3,4,5,6])\r\n",
    "s2 = pd.Series([\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"])\r\n",
    "# Terapkan method append\r\n",
    "s2_append_s1 = s2.append(s1)\r\n",
    "print(\"Series - append:\\n\", s2_append_s1)\r\n",
    "# Buat dataframe df1 dan df2\r\n",
    "df1 = pd.DataFrame({'a':[1,2],\r\n",
    "'b':[3,4]})\r\n",
    "df2 = pd.DataFrame({'b':[1,2],\r\n",
    "'a':[3,4]})\r\n",
    "# Terapkan method append\r\n",
    "df2_append_df1 = df2.append(df1)\r\n",
    "print(\"Dataframe - append:\\n\", df2_append_df1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concat"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Buat dataframe df1 dan df2\r\n",
    "df1 = pd.DataFrame({'a':[1,2],\r\n",
    "     'b':[3,4]})\r\n",
    "df2 = pd.DataFrame({'b':[1,2],\r\n",
    "     'a':[3,4]})\r\n",
    "# Terapkan method concat row-wise\r\n",
    "row_wise_concat = pd.concat([df2,df1])\r\n",
    "print(\"Row-wise - concat:\\n\", row_wise_concat)\r\n",
    "# Terapkan method concat column-wise\r\n",
    "col_wise_concat = pd.concat([df2,df1],axis=1)\r\n",
    "print(\"Column-wise - concat:\\n\", col_wise_concat)\r\n",
    "# Penambahan identifier --> membentuk hasil penggabungan multiindex\r\n",
    "multiindex_concat = pd.concat([df2,df1], axis=0, keys=['df1', 'df2'])\r\n",
    "print(\"Multiindex - concat:\\n\", multiindex_concat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Buat dataframe df1 dan df2\r\n",
    "df1 = pd.DataFrame({\r\n",
    "   'key':['k1','k2','k3','k4','k5'],\r\n",
    "   'val1':[200, 500, 0, 500, 100],\r\n",
    "   'val2':[30, 50, 100, 20, 10]\r\n",
    "})\r\n",
    "df2 = pd.DataFrame({\r\n",
    "   'key':['k1','k3','k5','k7','k10'],\r\n",
    "   'val3':[1,2,3,4,5],\r\n",
    "   'val4':[6,7,8,8,10]\r\n",
    "})\r\n",
    "# Merge yang ekivalen dengan SQL left join\r\n",
    "merge_df_left = pd.merge(left=df2, right=df1, how='left', left_on='key', right_on='key')\r\n",
    "print('Merge - Left:\\n', merge_df_left)\r\n",
    "# Merge yang ekivalen dengan SQL right join\r\n",
    "merge_df_right = pd.merge(left=df2, right=df1, how='right', left_on='key', right_on='key')\r\n",
    "print('Merge - Right:\\n', merge_df_right)\r\n",
    "# Merge yang ekivalen dengan SQL inner join\r\n",
    "merge_df_inner = pd.merge(left=df2, right=df1, how='inner', left_on='key', right_on='key')\r\n",
    "print('Merge - Inner:\\n', merge_df_inner)\r\n",
    "# Merge yang ekivalen dengan SQL outer join\r\n",
    "merge_df_outer = pd.merge(left=df2, right=df1, how='outer', left_on='key', right_on='key')\r\n",
    "print('Merge - Outer:\\n', merge_df_outer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Index value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Buat dataframe df1 dan df2\r\n",
    "df1 = pd.DataFrame({\r\n",
    "   'key':['k1','k2','k3','k4','k5'],\r\n",
    "   'val1':[200, 500, 0, 500, 100],\r\n",
    "   'val2':[30, 50, 100, 20, 10]\r\n",
    "}).set_index(['key','val2'])\r\n",
    "print('Dataframe 1:\\n', df1)\r\n",
    "df2 = pd.DataFrame({\r\n",
    "   'key':['k1','k3','k5','k7','k10'],\r\n",
    "   'val3':[1,2,3,4,5],\r\n",
    "   'val4':[6,7,8,8,10]\r\n",
    "}).set_index(['key','val3'])\r\n",
    "print('Dataframe 2:\\n', df2)\r\n",
    "# Merge dataframe yang memiliki multi index\r\n",
    "df_merge = pd.merge(df1.reset_index(),df2.reset_index())\r\n",
    "print('Merging dataframe:\\n', df_merge)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Outer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Buat dataframe df1 dan df2\r\n",
    "df1 = pd.DataFrame({\r\n",
    "   'key':['k1','k2','k3','k4','k5'],\r\n",
    "   'val1':[200, 500, 0, 500, 100],\r\n",
    "   'val2':[30, 50, 100, 20, 10]\r\n",
    "})\r\n",
    "df2 = pd.DataFrame({\r\n",
    "   'key':['k1','k3','k5','k7','k10'],\r\n",
    "   'val3':[1,2,3,4,5],\r\n",
    "   'val4':[6,7,8,8,10]\r\n",
    "})\r\n",
    "# Penerapan join dengan menggunakan set_index dan keyword how\r\n",
    "join_df = df1.set_index('key').join(df2.set_index('key'), how='outer')\r\n",
    "print(join_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Quiz\r\n",
    "# Diberikan dataframe sebagai berikut\r\n",
    "\r\n",
    "df1 = pd.DataFrame({\r\n",
    "   'key':['k1','k2','k3','k4','k5'],\r\n",
    "   'val1':[200, 500, 0, 500, 100],\r\n",
    "   'val2':[30, 50, 100, 20, 10],\r\n",
    "  \r\n",
    "})\r\n",
    "df2 = pd.DataFrame({\r\n",
    "   'key':['k1','k1','k5','k7','k10'],\r\n",
    "   'val3':[1,2,3,4,5],\r\n",
    "   'val4':[6,7,8,8,10]\r\n",
    "})\r\n",
    "\r\n",
    "pd.merge(df1, df2, validate=\"1:1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas', 'murid', 'pelajaran', 'nilai'])\r\n",
    "# Unique value pada setiap kolom data\r\n",
    "for column in data.columns:\r\n",
    "    print('Unique value %s: %s' % (column, data[column].unique()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pivot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "# Pivoting with single column measurement\r\n",
    "pivot1 = data.pivot(index='murid',columns='pelajaran',values='nilai')\r\n",
    "print('Pivoting with single column measurement:\\n', pivot1)\r\n",
    "# Pivoting with multiple column measurement\r\n",
    "pivot2 = data.pivot(index='murid',columns='pelajaran')\r\n",
    "print('Pivoting with multiple column measurement:\\n', pivot2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid', 'pelajaran','nilai'])\r\n",
    "# Creating pivot and assign pivot_tab dengan menggunakan keyword aggfunc='mean'\r\n",
    "pivot_tab_mean = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='mean')\r\n",
    "print('Creating pivot table -- aggfunc mean:\\n', pivot_tab_mean)\r\n",
    "# Creating pivot and assign pivot_tab dengan menggunakan keyword aggfunc='median'\r\n",
    "pivot_tab_median = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='median')\r\n",
    "print('Creating pivot table -- aggfunc median:\\n', pivot_tab_median)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "# Pivoting dataframe\r\n",
    "data_pivot = data.pivot_table(index='kelas',columns='pelajaran',values='nilai',aggfunc='mean').reset_index()\r\n",
    "print('Pivoting dataframe:\\n', data_pivot)\r\n",
    "# [1] Melting dataframe data_pivot\r\n",
    "data_melt_1 = pd.melt(data_pivot)\r\n",
    "print('Melting dataframe:\\n', data_melt_1)\r\n",
    "# [2] Melting dataframe data_pivot dengan id_vars\r\n",
    "data_melt_2 = pd.melt(data_pivot, id_vars='kelas')\r\n",
    "print('Melting dataframe dengan idvars:\\n', data_melt_2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "# Pivoting dataframe\r\n",
    "data_pivot = data.pivot_table(index='kelas',columns='pelajaran',values='nilai', aggfunc='mean').reset_index()\r\n",
    "print('Pivoting dataframe:\\n', data_pivot)\r\n",
    "# [3.a] Melting dataframe data_pivot dengan value_vars\r\n",
    "data_melt_3a = pd.melt(data_pivot, value_vars=['math'])\r\n",
    "print('Melting dataframe dengan value_vars:\\n', data_melt_3a)\r\n",
    "# [3.b] Melting dataframe data_pivot dengan id_vars dan value_vars\r\n",
    "data_melt_3b = pd.melt(data_pivot, id_vars='kelas', value_vars=['math'])\r\n",
    "print('Melting dataframe dengan id_vars dan value_vars:\\n', data_melt_3b)\r\n",
    "# [4] Melting dataframe data_pivot dengan id_vars, value_vars, var_name. dan value_name\r\n",
    "data_melt_4 = pd.melt(data_pivot, id_vars='kelas', value_vars=['english', 'math'], var_name='pelajaran', value_name='nilai')\r\n",
    "print('Melting dataframe dengan id_vars, value_vars, var_name. dan value_name:\\n', data_melt_4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Unstacking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "print('Dataframe:\\n', data)\r\n",
    "# Set index data untuk kolom kelas, murid, dan pelajaran\r\n",
    "data = data.set_index(['kelas','murid','pelajaran'])\r\n",
    "print('Dataframe multi index:\\n', data)\r\n",
    "# [1] Unstacking dataframe\r\n",
    "data_unstack_1 = data.unstack()\r\n",
    "print('Unstacking dataframe:\\n', data_unstack_1)\r\n",
    "# [2] Unstacking dengan specify level name\r\n",
    "data_unstack_2 = data.unstack(level='murid')\r\n",
    "print('Unstacking dataframe dengan level name:\\n', data_unstack_2)\r\n",
    "# [3] Unstacking dengan specify level position\r\n",
    "data_unstack_3 = data.unstack(level=1)\r\n",
    "print('Unstacking dataframe dengan level position:\\n', data_unstack_3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Perbandingan"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "data = data.set_index(['kelas','murid','pelajaran'])\r\n",
    "data_unstack = data.unstack(level=1)\r\n",
    "print('Dataframe:\\n', data_unstack)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# [1] Stacking dataframe\r\n",
    "data_stack = data_unstack.stack()\r\n",
    "print('Stacked dataframe:\\n', data_stack)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# [2] Tukar posisi index setelah stacking dataframe\r\n",
    "data_swap = data_stack.swaplevel(1,2)\r\n",
    "print('Swapped data:\\n', data_swap)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# [3] Melakukan sort_index pada stacking dataframe\r\n",
    "data_sort = data_swap.sort_index()\r\n",
    "print('Sorted data:\\n', data_sort)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Quis\r\n",
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "data = data.set_index(['kelas','murid','pelajaran'])\r\n",
    "data_unstack = data.unstack(level=[0,1])\r\n",
    "print('Dataframe:\\n', data_unstack)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data global_air_quality.csv\r\n",
    "global_air_quality = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "print('Lima data teratas:\\n', global_air_quality.head())\r\n",
    "# Melakukan pengecekan terhadap data\r\n",
    "print('Info global_air_quality:\\n', global_air_quality.info())\r\n",
    "# Melakukan count tanpa groupby\r\n",
    "print('Count tanpa groupby:\\n', global_air_quality.count())\r\n",
    "# Melakukan count dengan groupby \r\n",
    "gaq_groupby_count = global_air_quality.groupby('source_name').count()\r\n",
    "print('Count dengan groupby (5 data teratas):\\n', gaq_groupby_count.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agreegat\r\n",
    "## Fungsi dari agregrasi adalah menerapakan fungsi statistik dalam "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data global_air_quality.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country', 'city', 'pollutant', 'value']].pivot_table(index=['country', 'city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# [1] Group berdasarkan country dan terapkan aggregasi mean\r\n",
    "pollutant_mean = pollutant.groupby('country').mean()\r\n",
    "print('Rata-rata pollutant (5 teratas):\\n', pollutant_mean.head())\r\n",
    "# [2] Group berdasarkan country dan terapkan aggregasi std\r\n",
    "pollutant_std = pollutant.groupby('country').std().fillna(0)\r\n",
    "print('Standar deviasi pollutant (5 teratas):\\n', pollutant_std.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agregat berdasarkan sum"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# [3] Group berdasarkan country dan terapkan aggregasi sum\r\n",
    "pollutant_sum = pollutant.groupby('country').sum()\r\n",
    "print('Total pollutant (5 teratas):\\n', pollutant_sum.head())\r\n",
    "# [4] Group berdasarkan country dan terapkan aggregasi nunique\r\n",
    "pollutant_nunique = pollutant.groupby('country').nunique()\r\n",
    "print('Jumlah unique value pollutant (5 teratas):\\n', pollutant_nunique.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agregat lanjutan First dan Last"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# Group berdasarkan country dan terapkan aggregasi first\r\n",
    "pollutant_first = pollutant.groupby('country').min()\r\n",
    "print('Item pertama pollutant (5 teratas):\\n', pollutant_first.head())\r\n",
    "# Group berdasarkan country dan terapkan aggregasi last\r\n",
    "pollutant_last = pollutant.groupby('country').max()\r\n",
    "print('Item terakhir pollutant (5 teratas):\\n', pollutant_last.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# Group berdasarkan country dan terapkan aggregasi first\r\n",
    "pollutant_first = pollutant.groupby('country').first()\r\n",
    "print('Item pertama pollutant (5 teratas):\\n', pollutant_first.head())\r\n",
    "# Group berdasarkan country dan terapkan aggregasi last\r\n",
    "pollutant_last = pollutant.groupby('country').last()\r\n",
    "print('Item terakhir pollutant (5 teratas):\\n', pollutant_last.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# Group berdasarkan country dan terapkan aggregasi: min, median, mean, max\r\n",
    "multiagg = pollutant.groupby('country').agg(['min','median','mean','max'])\r\n",
    "print('Multiple aggregations (5 teratas):\\n', multiagg.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Groupby dengan Custom Aggregations\r\n",
    "Dengan membuat sebuah Python function (user defined) dapat menggunakan sebagai custom aggregation pada dataframe yang telah digroupby.\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "# Create sebuah function: iqr\r\n",
    "def iqr(series):\r\n",
    "\tQ1 = series.quantile(0.25)\r\n",
    "\tQ3 = series.quantile(0.75)\r\n",
    "\treturn Q3-Q1\r\n",
    "# Group berdasarkan country dan terapkan aggregasi dari function: iqr\r\n",
    "custom_agg = pollutant.groupby('country').agg(iqr)\r\n",
    "print('Custom aggregation (5 teratas):\\n', custom_agg.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Groupby dengan Custom Aggregations by dict\r\n",
    "Penggunaan custom aggregation lainnya pada dataframe yang telah digroupby dapat dilakukan dengan mempasskan sebuah dict yang berisi 'key' dict sebagai nama kolomnya dan 'value' dict adalah fungsi untuk aggregasi, baik user defined function atau yang telah tersedia."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# Function IQR\r\n",
    "def iqr(series):\r\n",
    " return series.quantile(0.75) - series.quantile(0.25)\r\n",
    "# Create custom aggregation using dict\r\n",
    "custom_agg_dict = pollutant['value'][['pm10','pm25','so2']].groupby('country').agg({\r\n",
    "   'pm10':'median',\r\n",
    "   'pm25':iqr,\r\n",
    "   'so2':iqr\r\n",
    "})\r\n",
    "print('\\nCetak 5 data teratas custom_agg_dict:\\n', custom_agg_dict.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Times Series in Pandas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\", parse_dates=True, index_col='timestamp')\r\n",
    "# Cetak 5 data teratas\r\n",
    "print(gaq.head())\r\n",
    "# Cetak info dari dataframe gaq\r\n",
    "print('info')\r\n",
    "print(gaq.info())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert To Date Time"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Cetak 5 data teratas\r\n",
    "print('Sebelum diubah dalam format datetime:\\n', gaq.head())\r\n",
    "# Ubah menjadi datetime\r\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\r\n",
    "gaq = gaq.set_index('timestamp')\r\n",
    "# Cetak 5 data teratas\r\n",
    "print('Sesudah diubah dalam format datetime:\\n', gaq.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Time Series in Pandas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Daily to weekly dan apply max\r\n",
    "# Daily to quaterly dan apply min"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load dataset https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv ')\r\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\r\n",
    "gaq = gaq.set_index('timestamp')\r\n",
    "print('Dataset sebelum di-downsampling (5 teratas):\\n', gaq.head())\r\n",
    "# [1] Downsampling dari daily to weekly dan kita hitung maksimum untuk seminggu\r\n",
    "gaq_weekly = gaq.resample('W').max()\r\n",
    "print('Downsampling daily to weekly - max (5 teratas):\\n', gaq_weekly.head())\r\n",
    "# [2] Downsampling dari daily to quaterly dan kita hitung minimumnya untuk tiap quarter\r\n",
    "gaq_quaterly = gaq.resample('Q').min()\r\n",
    "print('Downsampling daily to quaterly - min (5 teratas):\\n', gaq_quaterly.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# proses upsampling daily to hourly dan apply mean"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\r\n",
    "gaq = gaq.set_index('timestamp')\r\n",
    "print('Dataset sebelum di-upsampling (5 teratas):\\n', gaq.head())\r\n",
    "# Upsampling dari daily to hourly dan kita hitung reratanya\r\n",
    "gaq_hourly = gaq.resample('H').mean()\r\n",
    "print('Upsampling daily to hourly - mean (5 teratas):\\n', gaq_hourly.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# daily to bi-monthly, kemudian hitung rata-ratanya, jika ada nilai NaN maka dapat diisi dengan fillna method = 'bfill'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\r\n",
    "gaq = gaq.set_index('timestamp')\r\n",
    "print('Dataset sebelum di-resampling (5 teratas):\\n', gaq.head())\r\n",
    "# Resample dari daily to 2 monthly, hitung reratanya, dan fillna = 'bfill'\r\n",
    "gaq_2monthly = gaq.resample('2M').mean().fillna(method='bfill')\r\n",
    "print('Resampling daily to 2 monthly - mean - ffill (5 teratas):\\n', gaq_2monthly.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\r\n",
    "gaq = gaq.set_index('timestamp')\r\n",
    "# [1] Membuat pivot table yang menunjukkan waktu di baris nya dan masing-masing value dari pollutant nya dalam kolom\r\n",
    "gaq_viz = gaq[['pollutant','value']].reset_index().set_index(['timestamp','pollutant'])\r\n",
    "gaq_viz = gaq_viz.pivot_table(index='timestamp', columns='pollutant', aggfunc='mean').fillna(0)\r\n",
    "gaq_viz.columns = gaq_viz.columns.droplevel(0)\r\n",
    "print('Data (5 teratas):\\n', gaq_viz.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# sdf"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}