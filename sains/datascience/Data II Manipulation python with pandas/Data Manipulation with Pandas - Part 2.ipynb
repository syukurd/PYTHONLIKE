{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Append"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Buat series of int (s1) dan series of string (s2)\r\n",
    "s1 = pd.Series([1,2,3,4,5,6])\r\n",
    "s2 = pd.Series([\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"])\r\n",
    "# Terapkan method append\r\n",
    "s2_append_s1 = s2.append(s1)\r\n",
    "print(\"Series - append:\\n\", s2_append_s1)\r\n",
    "# Buat dataframe df1 dan df2\r\n",
    "df1 = pd.DataFrame({'a':[1,2],\r\n",
    "'b':[3,4]})\r\n",
    "df2 = pd.DataFrame({'b':[1,2],\r\n",
    "'a':[3,4]})\r\n",
    "# Terapkan method append\r\n",
    "df2_append_df1 = df2.append(df1)\r\n",
    "print(\"Dataframe - append:\\n\", df2_append_df1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concat"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Buat dataframe df1 dan df2\r\n",
    "df1 = pd.DataFrame({'a':[1,2],\r\n",
    "     'b':[3,4]})\r\n",
    "df2 = pd.DataFrame({'b':[1,2],\r\n",
    "     'a':[3,4]})\r\n",
    "# Terapkan method concat row-wise\r\n",
    "row_wise_concat = pd.concat([df2,df1])\r\n",
    "print(\"Row-wise - concat:\\n\", row_wise_concat)\r\n",
    "# Terapkan method concat column-wise\r\n",
    "col_wise_concat = pd.concat([df2,df1],axis=1)\r\n",
    "print(\"Column-wise - concat:\\n\", col_wise_concat)\r\n",
    "# Penambahan identifier --> membentuk hasil penggabungan multiindex\r\n",
    "multiindex_concat = pd.concat([df2,df1], axis=0, keys=['df1', 'df2'])\r\n",
    "print(\"Multiindex - concat:\\n\", multiindex_concat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Buat dataframe df1 dan df2\r\n",
    "df1 = pd.DataFrame({\r\n",
    "   'key':['k1','k2','k3','k4','k5'],\r\n",
    "   'val1':[200, 500, 0, 500, 100],\r\n",
    "   'val2':[30, 50, 100, 20, 10]\r\n",
    "})\r\n",
    "df2 = pd.DataFrame({\r\n",
    "   'key':['k1','k3','k5','k7','k10'],\r\n",
    "   'val3':[1,2,3,4,5],\r\n",
    "   'val4':[6,7,8,8,10]\r\n",
    "})\r\n",
    "# Merge yang ekivalen dengan SQL left join\r\n",
    "merge_df_left = pd.merge(left=df2, right=df1, how='left', left_on='key', right_on='key')\r\n",
    "print('Merge - Left:\\n', merge_df_left)\r\n",
    "# Merge yang ekivalen dengan SQL right join\r\n",
    "merge_df_right = pd.merge(left=df2, right=df1, how='right', left_on='key', right_on='key')\r\n",
    "print('Merge - Right:\\n', merge_df_right)\r\n",
    "# Merge yang ekivalen dengan SQL inner join\r\n",
    "merge_df_inner = pd.merge(left=df2, right=df1, how='inner', left_on='key', right_on='key')\r\n",
    "print('Merge - Inner:\\n', merge_df_inner)\r\n",
    "# Merge yang ekivalen dengan SQL outer join\r\n",
    "merge_df_outer = pd.merge(left=df2, right=df1, how='outer', left_on='key', right_on='key')\r\n",
    "print('Merge - Outer:\\n', merge_df_outer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Index value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Buat dataframe df1 dan df2\r\n",
    "df1 = pd.DataFrame({\r\n",
    "   'key':['k1','k2','k3','k4','k5'],\r\n",
    "   'val1':[200, 500, 0, 500, 100],\r\n",
    "   'val2':[30, 50, 100, 20, 10]\r\n",
    "}).set_index(['key','val2'])\r\n",
    "print('Dataframe 1:\\n', df1)\r\n",
    "df2 = pd.DataFrame({\r\n",
    "   'key':['k1','k3','k5','k7','k10'],\r\n",
    "   'val3':[1,2,3,4,5],\r\n",
    "   'val4':[6,7,8,8,10]\r\n",
    "}).set_index(['key','val3'])\r\n",
    "print('Dataframe 2:\\n', df2)\r\n",
    "# Merge dataframe yang memiliki multi index\r\n",
    "df_merge = pd.merge(df1.reset_index(),df2.reset_index())\r\n",
    "print('Merging dataframe:\\n', df_merge)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Outer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Buat dataframe df1 dan df2\r\n",
    "df1 = pd.DataFrame({\r\n",
    "   'key':['k1','k2','k3','k4','k5'],\r\n",
    "   'val1':[200, 500, 0, 500, 100],\r\n",
    "   'val2':[30, 50, 100, 20, 10]\r\n",
    "})\r\n",
    "df2 = pd.DataFrame({\r\n",
    "   'key':['k1','k3','k5','k7','k10'],\r\n",
    "   'val3':[1,2,3,4,5],\r\n",
    "   'val4':[6,7,8,8,10]\r\n",
    "})\r\n",
    "# Penerapan join dengan menggunakan set_index dan keyword how\r\n",
    "join_df = df1.set_index('key').join(df2.set_index('key'), how='outer')\r\n",
    "print(join_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Quiz\r\n",
    "# Diberikan dataframe sebagai berikut\r\n",
    "\r\n",
    "df1 = pd.DataFrame({\r\n",
    "   'key':['k1','k2','k3','k4','k5'],\r\n",
    "   'val1':[200, 500, 0, 500, 100],\r\n",
    "   'val2':[30, 50, 100, 20, 10],\r\n",
    "  \r\n",
    "})\r\n",
    "df2 = pd.DataFrame({\r\n",
    "   'key':['k1','k1','k5','k7','k10'],\r\n",
    "   'val3':[1,2,3,4,5],\r\n",
    "   'val4':[6,7,8,8,10]\r\n",
    "})\r\n",
    "\r\n",
    "pd.merge(df1, df2, validate=\"1:1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas', 'murid', 'pelajaran', 'nilai'])\r\n",
    "# Unique value pada setiap kolom data\r\n",
    "for column in data.columns:\r\n",
    "    print('Unique value %s: %s' % (column, data[column].unique()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pivot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "# Pivoting with single column measurement\r\n",
    "pivot1 = data.pivot(index='murid',columns='pelajaran',values='nilai')\r\n",
    "print('Pivoting with single column measurement:\\n', pivot1)\r\n",
    "# Pivoting with multiple column measurement\r\n",
    "pivot2 = data.pivot(index='murid',columns='pelajaran')\r\n",
    "print('Pivoting with multiple column measurement:\\n', pivot2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid', 'pelajaran','nilai'])\r\n",
    "# Creating pivot and assign pivot_tab dengan menggunakan keyword aggfunc='mean'\r\n",
    "pivot_tab_mean = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='mean')\r\n",
    "print('Creating pivot table -- aggfunc mean:\\n', pivot_tab_mean)\r\n",
    "# Creating pivot and assign pivot_tab dengan menggunakan keyword aggfunc='median'\r\n",
    "pivot_tab_median = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='median')\r\n",
    "print('Creating pivot table -- aggfunc median:\\n', pivot_tab_median)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Melting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "# Pivoting dataframe\r\n",
    "data_pivot = data.pivot_table(index='kelas',columns='pelajaran',values='nilai',aggfunc='mean').reset_index()\r\n",
    "print('Pivoting dataframe:\\n', data_pivot)\r\n",
    "# [1] Melting dataframe data_pivot\r\n",
    "data_melt_1 = pd.melt(data_pivot)\r\n",
    "print('Melting dataframe:\\n', data_melt_1)\r\n",
    "# [2] Melting dataframe data_pivot dengan id_vars\r\n",
    "data_melt_2 = pd.melt(data_pivot, id_vars='kelas')\r\n",
    "print('Melting dataframe dengan idvars:\\n', data_melt_2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "# Pivoting dataframe\r\n",
    "data_pivot = data.pivot_table(index='kelas',columns='pelajaran',values='nilai', aggfunc='mean').reset_index()\r\n",
    "print('Pivoting dataframe:\\n', data_pivot)\r\n",
    "# [3.a] Melting dataframe data_pivot dengan value_vars\r\n",
    "data_melt_3a = pd.melt(data_pivot, value_vars=['math'])\r\n",
    "print('Melting dataframe dengan value_vars:\\n', data_melt_3a)\r\n",
    "# [3.b] Melting dataframe data_pivot dengan id_vars dan value_vars\r\n",
    "data_melt_3b = pd.melt(data_pivot, id_vars='kelas', value_vars=['math'])\r\n",
    "print('Melting dataframe dengan id_vars dan value_vars:\\n', data_melt_3b)\r\n",
    "# [4] Melting dataframe data_pivot dengan id_vars, value_vars, var_name. dan value_name\r\n",
    "data_melt_4 = pd.melt(data_pivot, id_vars='kelas', value_vars=['english', 'math'], var_name='pelajaran', value_name='nilai')\r\n",
    "print('Melting dataframe dengan id_vars, value_vars, var_name. dan value_name:\\n', data_melt_4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Unstacking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "print('Dataframe:\\n', data)\r\n",
    "# Set index data untuk kolom kelas, murid, dan pelajaran\r\n",
    "data = data.set_index(['kelas','murid','pelajaran'])\r\n",
    "print('Dataframe multi index:\\n', data)\r\n",
    "# [1] Unstacking dataframe\r\n",
    "data_unstack_1 = data.unstack()\r\n",
    "print('Unstacking dataframe:\\n', data_unstack_1)\r\n",
    "# [2] Unstacking dengan specify level name\r\n",
    "data_unstack_2 = data.unstack(level='murid')\r\n",
    "print('Unstacking dataframe dengan level name:\\n', data_unstack_2)\r\n",
    "# [3] Unstacking dengan specify level position\r\n",
    "data_unstack_3 = data.unstack(level=1)\r\n",
    "print('Unstacking dataframe dengan level position:\\n', data_unstack_3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Perbandingan"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "data = data.set_index(['kelas','murid','pelajaran'])\r\n",
    "data_unstack = data.unstack(level=1)\r\n",
    "print('Dataframe:\\n', data_unstack)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# [1] Stacking dataframe\r\n",
    "data_stack = data_unstack.stack()\r\n",
    "print('Stacked dataframe:\\n', data_stack)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# [2] Tukar posisi index setelah stacking dataframe\r\n",
    "data_swap = data_stack.swaplevel(1,2)\r\n",
    "print('Swapped data:\\n', data_swap)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# [3] Melakukan sort_index pada stacking dataframe\r\n",
    "data_sort = data_swap.sort_index()\r\n",
    "print('Sorted data:\\n', data_sort)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Quis\r\n",
    "import pandas as pd\r\n",
    "# Dataframe\r\n",
    "data = pd.DataFrame({\r\n",
    "  'kelas': 6*['A'] + 6*['B'],\r\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\r\n",
    "  'pelajaran': 6*['math','english'],\r\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\r\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\r\n",
    "data = data.set_index(['kelas','murid','pelajaran'])\r\n",
    "data_unstack = data.unstack(level=[0,1])\r\n",
    "print('Dataframe:\\n', data_unstack)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data global_air_quality.csv\r\n",
    "global_air_quality = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "print('Lima data teratas:\\n', global_air_quality.head())\r\n",
    "# Melakukan pengecekan terhadap data\r\n",
    "print('Info global_air_quality:\\n', global_air_quality.info())\r\n",
    "# Melakukan count tanpa groupby\r\n",
    "print('Count tanpa groupby:\\n', global_air_quality.count())\r\n",
    "# Melakukan count dengan groupby \r\n",
    "gaq_groupby_count = global_air_quality.groupby('source_name').count()\r\n",
    "print('Count dengan groupby (5 data teratas):\\n', gaq_groupby_count.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agreegat\r\n",
    "## Fungsi dari agregrasi adalah menerapakan fungsi statistik dalam "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data global_air_quality.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country', 'city', 'pollutant', 'value']].pivot_table(index=['country', 'city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# [1] Group berdasarkan country dan terapkan aggregasi mean\r\n",
    "pollutant_mean = pollutant.groupby('country').mean()\r\n",
    "print('Rata-rata pollutant (5 teratas):\\n', pollutant_mean.head())\r\n",
    "# [2] Group berdasarkan country dan terapkan aggregasi std\r\n",
    "pollutant_std = pollutant.groupby('country').std().fillna(0)\r\n",
    "print('Standar deviasi pollutant (5 teratas):\\n', pollutant_std.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agregat berdasarkan sum"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# [3] Group berdasarkan country dan terapkan aggregasi sum\r\n",
    "pollutant_sum = pollutant.groupby('country').sum()\r\n",
    "print('Total pollutant (5 teratas):\\n', pollutant_sum.head())\r\n",
    "# [4] Group berdasarkan country dan terapkan aggregasi nunique\r\n",
    "pollutant_nunique = pollutant.groupby('country').nunique()\r\n",
    "print('Jumlah unique value pollutant (5 teratas):\\n', pollutant_nunique.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agregat lanjutan First dan Last"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# Group berdasarkan country dan terapkan aggregasi first\r\n",
    "pollutant_first = pollutant.groupby('country').min()\r\n",
    "print('Item pertama pollutant (5 teratas):\\n', pollutant_first.head())\r\n",
    "# Group berdasarkan country dan terapkan aggregasi last\r\n",
    "pollutant_last = pollutant.groupby('country').max()\r\n",
    "print('Item terakhir pollutant (5 teratas):\\n', pollutant_last.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# Group berdasarkan country dan terapkan aggregasi first\r\n",
    "pollutant_first = pollutant.groupby('country').first()\r\n",
    "print('Item pertama pollutant (5 teratas):\\n', pollutant_first.head())\r\n",
    "# Group berdasarkan country dan terapkan aggregasi last\r\n",
    "pollutant_last = pollutant.groupby('country').last()\r\n",
    "print('Item terakhir pollutant (5 teratas):\\n', pollutant_last.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# Group berdasarkan country dan terapkan aggregasi: min, median, mean, max\r\n",
    "multiagg = pollutant.groupby('country').agg(['min','median','mean','max'])\r\n",
    "print('Multiple aggregations (5 teratas):\\n', multiagg.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Groupby dengan Custom Aggregations\r\n",
    "Dengan membuat sebuah Python function (user defined) dapat menggunakan sebagai custom aggregation pada dataframe yang telah digroupby.\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "# Create sebuah function: iqr\r\n",
    "def iqr(series):\r\n",
    "\tQ1 = series.quantile(0.25)\r\n",
    "\tQ3 = series.quantile(0.75)\r\n",
    "\treturn Q3-Q1\r\n",
    "# Group berdasarkan country dan terapkan aggregasi dari function: iqr\r\n",
    "custom_agg = pollutant.groupby('country').agg(iqr)\r\n",
    "print('Custom aggregation (5 teratas):\\n', custom_agg.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Groupby dengan Custom Aggregations by dict\r\n",
    "Penggunaan custom aggregation lainnya pada dataframe yang telah digroupby dapat dilakukan dengan mempasskan sebuah dict yang berisi 'key' dict sebagai nama kolomnya dan 'value' dict adalah fungsi untuk aggregasi, baik user defined function atau yang telah tersedia."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load data https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Create variabel pollutant \r\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\r\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\r\n",
    "# Function IQR\r\n",
    "def iqr(series):\r\n",
    " return series.quantile(0.75) - series.quantile(0.25)\r\n",
    "# Create custom aggregation using dict\r\n",
    "custom_agg_dict = pollutant['value'][['pm10','pm25','so2']].groupby('country').agg({\r\n",
    "   'pm10':'median',\r\n",
    "   'pm25':iqr,\r\n",
    "   'so2':iqr\r\n",
    "})\r\n",
    "print('\\nCetak 5 data teratas custom_agg_dict:\\n', custom_agg_dict.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Times Series in Pandas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\", parse_dates=True, index_col='timestamp')\r\n",
    "# Cetak 5 data teratas\r\n",
    "print(gaq.head())\r\n",
    "# Cetak info dari dataframe gaq\r\n",
    "print('info')\r\n",
    "print(gaq.info())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert To Date Time"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "# Cetak 5 data teratas\r\n",
    "print('Sebelum diubah dalam format datetime:\\n', gaq.head())\r\n",
    "# Ubah menjadi datetime\r\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\r\n",
    "gaq = gaq.set_index('timestamp')\r\n",
    "# Cetak 5 data teratas\r\n",
    "print('Sesudah diubah dalam format datetime:\\n', gaq.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Time Series in Pandas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Daily to weekly dan apply max\r\n",
    "# Daily to quaterly dan apply min"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "# Load dataset https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv\r\n",
    "gaq = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/LO4/global_air_quality_4000rows.csv')\r\n",
    "gaq['timestamp'] = pd.to_datetime(gaq['timestamp'])\r\n",
    "gaq = gaq.set_index([gaq['timestamp']])\r\n",
    "print('Dataset sebelum di-downsampling (5 teratas):\\n', gaq.head())\r\n",
    "# [1] Downsampling dari daily to weekly dan kita hitung maksimum untuk seminggu\r\n",
    "gaq_weekly = gaq.resample('A').max()\r\n",
    "print('Downsampling daily to weekly - max (5 teratas):\\n', gaq_weekly.head())\r\n",
    "# [2] Downsampling dari daily to quaterly dan kita hitung minimumnya untuk tiap quarter\r\n",
    "gaq_quaterly = gaq.resample('Q')\r\n",
    "print('Downsampling daily to quaterly - min (5 teratas):\\n', gaq_quaterly.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset sebelum di-downsampling (5 teratas):\n",
      "                                                   location       city country  \\\n",
      "timestamp                                                                       \n",
      "2017-01-18 16:00:00+00:00                  MOBILE-KICKAPOO    LINCOLN      US   \n",
      "2020-04-07 20:00:00+00:00                  Oxford St Ebbes     Oxford      GB   \n",
      "2020-04-07 19:00:00+00:00                 BROADWAY (South)  St. Louis      US   \n",
      "2020-04-07 18:30:00+00:00  Deen Dayal Nagar, Sagar - MPPCB      Sagar      IN   \n",
      "2020-04-07 20:00:00+00:00                        Manglerud       Oslo      NO   \n",
      "\n",
      "                          pollutant  value                 timestamp   unit  \\\n",
      "timestamp                                                                     \n",
      "2017-01-18 16:00:00+00:00      pm10   7.00 2017-01-18 16:00:00+00:00  µg/m³   \n",
      "2020-04-07 20:00:00+00:00       no2  30.00 2020-04-07 20:00:00+00:00  µg/m³   \n",
      "2020-04-07 19:00:00+00:00      pm25   6.10 2020-04-07 19:00:00+00:00  µg/m³   \n",
      "2020-04-07 18:30:00+00:00      pm25  23.67 2020-04-07 18:30:00+00:00  µg/m³   \n",
      "2020-04-07 20:00:00+00:00      pm10  27.06 2020-04-07 20:00:00+00:00  µg/m³   \n",
      "\n",
      "                          source_name   latitude  longitude  \\\n",
      "timestamp                                                     \n",
      "2017-01-18 16:00:00+00:00      AirNow  35.488400 -97.090280   \n",
      "2020-04-07 20:00:00+00:00       DEFRA  51.744804  -1.260278   \n",
      "2020-04-07 19:00:00+00:00      AirNow  38.542500 -90.263610   \n",
      "2020-04-07 18:30:00+00:00       caaqm  23.864016  78.802895   \n",
      "2020-04-07 20:00:00+00:00      Norway  59.898690  10.814950   \n",
      "\n",
      "                           averaged_over_in_hours  \n",
      "timestamp                                          \n",
      "2017-01-18 16:00:00+00:00                    1.00  \n",
      "2020-04-07 20:00:00+00:00                    1.00  \n",
      "2020-04-07 19:00:00+00:00                    1.00  \n",
      "2020-04-07 18:30:00+00:00                    0.25  \n",
      "2020-04-07 20:00:00+00:00                    1.00  \n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 4, placement implies 6",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10072/1240456407.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dataset sebelum di-downsampling (5 teratas):\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgaq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# [1] Downsampling dari daily to weekly dan kita hitung maksimum untuk seminggu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgaq_weekly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgaq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downsampling daily to weekly - max (5 teratas):\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgaq_weekly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# [2] Downsampling dari daily to quaterly dan kita hitung minimumnya untuk tiap quarter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\resample.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, _method, min_count, *args, **kwargs)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_resampler_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_downsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGroupBy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\resample.py\u001b[0m in \u001b[0;36m_downsample\u001b[1;34m(self, how, **kwargs)\u001b[0m\n\u001b[0;32m   1078\u001b[0m         \u001b[1;31m# we are downsampling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m         \u001b[1;31m# we want to call the actual grouper method here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_loffset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    943\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_mangle_lambdas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\aggregation.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(obj, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_aggregate_string_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0marg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAggFuncTypeDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_try_aggregate_string_function\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[1;31m# people may try to aggregate on a non-callable attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mmax\u001b[1;34m(self, numeric_only, min_count)\u001b[0m\n\u001b[0;32m   1674\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_groupby_agg_method_template\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"max\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1675\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1676\u001b[1;33m         return self._agg_general(\n\u001b[0m\u001b[0;32m   1677\u001b[0m             \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"max\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_agg_general\u001b[1;34m(self, numeric_only, min_count, alias, npfunc)\u001b[0m\n\u001b[0;32m   1022\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m                 result = self._cython_agg_general(\n\u001b[0m\u001b[0;32m   1025\u001b[0m                     \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m                     \u001b[0malt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnpfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m     ) -> DataFrame:\n\u001b[1;32m-> 1015\u001b[1;33m         agg_mgr = self._cython_agg_blocks(\n\u001b[0m\u001b[0;32m   1016\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_cython_agg_blocks\u001b[1;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[0;32m   1116\u001b[0m         \u001b[1;31m#  continue and exclude the block\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m         \u001b[1;31m# NotImplementedError -> \"ohlc\" with wrong dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1118\u001b[1;33m         \u001b[0mnew_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split_op_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Block\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_split_op_result\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(self, values, placement)\u001b[0m\n\u001b[0;32m    284\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_block_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_block_same_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[0;32m   2740\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2742\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    143\u001b[0m                 \u001b[1;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[1;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 4, placement implies 6"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}